{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import rawpy\n",
    "import exifread\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from GaussianPyramid import HDRPyramid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tiles(image, tile_size, stride):\n",
    "    if isinstance(tile_size, int):\n",
    "        tile_size = (tile_size, tile_size)\n",
    "    if isinstance(stride, int):\n",
    "        stride = (stride, stride)\n",
    "    tiles = []\n",
    "    h, w = image.shape\n",
    "    tile_size_h, tile_size_w = tile_size\n",
    "    stride_h, stride_w = stride\n",
    "    for i in range(0, h - tile_size_h + 1, stride_h):\n",
    "        row = []\n",
    "        for j in range(0, w - tile_size_w + 1, stride_w):\n",
    "            tile = image[i : i + tile_size_h, j : j + tile_size_w]\n",
    "            row.append(tile)\n",
    "        tiles.append(row)\n",
    "    tiles = np.array(tiles)\n",
    "    return tiles\n",
    "\n",
    "def isTypeInt(image):\n",
    "    return image.dtype in [np.uint8, np.uint16, np.uint32, np.uint64, np.int8, np.int16, np.int32, np.int64, np.uint]\n",
    "\n",
    "def downsample_bayer(image):\n",
    "    R = image[0 :: 2, 0 ::2] # 红色通道，取偶数行和偶数列的像素\n",
    "    G1 = image[0 :: 2, 1 :: 2] # 绿色通道1， 取偶数行和奇数列的像素\n",
    "    G2 = image[1 :: 2, 0 :: 2] # 绿色通道2，取奇数行和偶数列的像素\n",
    "    B = image[1 :: 2,  1 :: 2] # 蓝色通道，取奇数行和奇数列的像素\n",
    "    if isTypeInt(image):\n",
    "        return np.right_shift(R + G1 + G2 + B + 2, 2)\n",
    "    else:\n",
    "        return (R + G1 + G2 + B) * 0.25\n",
    "\n",
    "\n",
    "def computer_tiles_distance(refTiles, altTiles, offsets):\n",
    "    \"\"\"\n",
    "    [TODO] 理解并独立地实现这个功能\n",
    "    \"\"\"\n",
    "    m, n, ts, _ = refTiles.shape\n",
    "    h, w, _ = offsets.shape\n",
    "    res = np.zeros(shape=(h, w), dtype=refTiles.dtype)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            # offset value\n",
    "            off_i = offsets[i, j, 0]\n",
    "            off_j = offsets[i, j, 1]\n",
    "            # reference index\n",
    "            ri = i * (ts // 2)\n",
    "            rj = j * (ts // 2)\n",
    "            di = ri + int(off_i + (0.5 if off_i >= 0 else -0.5))\n",
    "            dj = rj + int(off_j + (0.5 if off_j >= 0 else -0.5))\n",
    "            di = 0 if di < 0 else (m - 1 if di > m - 1 else di)\n",
    "            dj = 0 if dj < 0 else (n - 1 if dj > n - 1 else dj)\n",
    "            dst = 0\n",
    "            for p in range(ts):\n",
    "                for q in range(ts):\n",
    "                    dst += np.abs(refTiles[ri, rj, p, q] - altTiles[di, dj, p, q])\n",
    "            res[i, j] = dst   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "refIndex = 0\n",
    "rawBayers = []\n",
    "burstPath = \"/home/lianghao/Documents/Learning/ISP/Image/IPOL_hdrplus_gopro_raw_bursts/hand_iso1600/\"\n",
    "alignmen_params = {\n",
    "\t\t\t\t'mode': 'bayer',  # images are single image Bayer / Color Filter Arrays\n",
    "\t\t\t\t'tuning': {\n",
    "\t\t\t\t\t# WARNING: these parameters are defined fine-to-coarse!\n",
    "\t\t\t\t\t'factors': [1, 2, 4, 4],\n",
    "\t\t\t\t\t'tileSizes': [16, 16, 16, 8],\n",
    "\t\t\t\t\t'searchRadia': [1, 4, 4, 4],\n",
    "\t\t\t\t\t'distances': ['L1', 'L2', 'L2', 'L2'],\n",
    "\t\t\t\t\t'subpixels': [False, True, True, True]  # if you want to compute subpixel tile alignment at each pyramid level\n",
    "\t\t\t\t},\n",
    "\t\t\t\t# rawpy parameters for images with motion fields\n",
    "\t\t\t\t'rawpyArgs': {\n",
    "\t\t\t\t\t'demosaic_algorithm' : rawpy.DemosaicAlgorithm.AHD,  # used in HDR+ supplement\n",
    "\t\t\t\t\t'half_size' : False,\n",
    "\t\t\t\t\t'use_camera_wb' : True,\n",
    "\t\t\t\t\t'use_auto_wb' : False,\n",
    "\t\t\t\t\t'no_auto_bright': True,\n",
    "\t\t\t\t\t'output_color' : rawpy.ColorSpace.sRGB,  # sRGB\n",
    "\t\t\t\t\t'output_bps' : 8\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'writeMotionFields': False,\n",
    "\t\t\t\t'writeAlignedTiles': False\n",
    "\t\t\t}\n",
    "\n",
    "rawPathList = glob.glob(os.path.join(burstPath, \"*.dng\"))\n",
    "rawPathList.sort()\n",
    "for rawPath in rawPathList:\n",
    "    with rawpy.imread(rawPath) as rawObject:\n",
    "        rawBayers.append(rawObject.raw_image.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rawpy.imread(rawPathList[refIndex]) as refRawpy:\n",
    "    blackLevel = refRawpy.black_level_per_channel.copy()\n",
    "    whiteLevel = refRawpy.white_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = rawBayers[refIndex].shape\n",
    "if alignmen_params[\"mode\"] == \"bayer\":\n",
    "    tileSize = 2 * alignmen_params['tuning']['tileSizes'][0]\n",
    "else:\n",
    "    tileSize = alignmen_params['tuning']['tileSizes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding setting \n",
    "padding_height = (tileSize - h % tileSize) % tileSize\n",
    "padding_width = (tileSize - w % tileSize) % tileSize\n",
    "padding_overlap_height, padding_overlap_width = tileSize // 2, tileSize // 2\n",
    "padding_top = padding_overlap_height\n",
    "padding_bottom = padding_overlap_height + padding_height\n",
    "padding_left = padding_overlap_width\n",
    "padding_right = padding_overlap_width + padding_left\n",
    "\n",
    "images_padding = []\n",
    "for i in range(len(rawBayers)):\n",
    "    im = np.pad(rawBayers[i], ((padding_top, padding_bottom), (padding_left, padding_right)), mode=\"symmetric\")\n",
    "    images_padding.append(im)\n",
    "\n",
    "reference = images_padding[refIndex]\n",
    "alternatives = [images_padding[i] for i in range(len(images_padding)) if i != refIndex]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implements the coarse-to-fine alignment on 4-level gaussian pyramids as defined in Algorithm 1 of Section 3 of the IPOL article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors, tileSizes, distances, searchRadia and subpixels are described fine-to-coarse\n",
    "factors = [1, 2, 4, 4]\n",
    "tile_sizes =  [16, 16, 16, 8]\n",
    "search_radia = [1, 4, 4, 4]\n",
    "distances = ['L1', 'L2', 'L2', 'L2']\n",
    "subpixels = [False, True, True, True]\n",
    "\n",
    "upsampling_factors = factors[1 : ] + [1]\n",
    "previous_tile_sizes = tile_sizes[1:] + [None]\n",
    "\n",
    "# If dealing with raw images, 2x2 bayer pixels block are averaged\n",
    "# (motion can then only be multiples of 2 pixels in original image size)\n",
    "# 对参考帧进行下采样2倍\n",
    "imRef = downsample_bayer(reference)\n",
    "tile_size = 2 * tile_sizes[0]\n",
    "refTiles = generate_tiles(reference, tile_size, tile_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储对齐瓦片\n",
    "aligned_tiles = np.empty(((len(images_padding),) + refTiles.shape), dtype=refTiles.dtype) \n",
    "aligned_tiles[0] = refTiles # 参考帧的瓦片作为对齐的初始值\n",
    "# 备选帧的瓦片对参考帧的瓦片的移动向量\n",
    "motion_vectors = np.empty((len(alternatives), refTiles.shape[0], refTiles.shape[1], 2), dtype=int)\n",
    "# 构建参考帧的4层从粗corse到细fine的金字塔\n",
    "hdrPyramid = HDRPyramid()\n",
    "refPyramid = hdrPyramid.gaussian_pyramid(image=imRef, factors=factors, ksize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每个备选帧对齐到参考帧\n",
    "for i, alternateImg in enumerate(alternatives):\n",
    "    # downsample bayer raw to grayscale\n",
    "    im_alter = downsample_bayer(alternateImg)\n",
    "    # 生成备选帧的4层由粗到细的金字塔\n",
    "    alternatePyramid = hdrPyramid.gaussian_pyramid(im_alter, factors)\n",
    "    # 金字塔由粗到细渐进式地对齐\n",
    "    aligments = None\n",
    "    for lv in range(len(refPyramid)):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "金字塔对齐"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对之前对齐的offset进行上采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_alignments(refer_pyramid, alter_pyramid, pre_alignments, up_factor, tile_size, pre_tile_size):\n",
    "    \"\"\"\n",
    "    [TODO] : 理解并掌握该函数的原理和实现方法\n",
    "    \"\"\"\n",
    "    # 对金字塔上一层估计的偏移量进行上采样\n",
    "    pre_alignments = pre_alignments * up_factor\n",
    "    # 不同分辨率上采样因子和瓦片大小导致不同的向量重复率\n",
    "    repeat_factor = upsampling_factors // (tile_size // pre_tile_size)\n",
    "    upsample_alignments = pre_alignments.repeat(repeat_factor, 0).repeat(repeat_factor, 1)\n",
    "    h, w = upsample_alignments.shape[:2]\n",
    "    # 镜像填充mirror避免边缘效应\n",
    "    pad_pre_alignments = np.pad(pre_alignments, pad_width=((1, ), (1, ), (0, )), mode='edge')\n",
    "    # 创建一个最近邻居的掩码，指定使用的偏移量以获得正确的索引\n",
    "    tile = np.zeros((repeat_factor, repeat_factor, 2, 2), dtype=np.int32)\n",
    "    tile[:(repeat_factor // 2), :(repeat_factor // 2)] = [[-1, 0], [0, -1]] # 左上\n",
    "    tile[:(repeat_factor // 2), (repeat_factor // 2) : ] = [[-1, 0], [0, 1]] # 右上\n",
    "    tile[:(repeat_factor // 2):, :(repeat_factor // 2)] = [[1, 0], [0, -1]] # 左下\n",
    "    tile[(repeat_factor // 2):, (repeat_factor // 2) : ] = [[1, 0], [0, 1]] # 右下\n",
    "    \n",
    "    neighborMask = np.tile(tile, (upsample_alignments.shape[0] // repeat_factor, upsample_alignments.shape[1] // repeat_factor, 1, 1))\n",
    "    # Compute the indices of the neighbors using the offsets mask\n",
    "    ti1 = np.repeat(np.clip(2 + np.arange(h) // repeat_factor + neighborMask[:, 0, 0, 0], 0, pad_pre_alignments.shape[0] - 1).reshape(h, 1), w, axis=1).reshape(h * w)\n",
    "    ti2 = np.repeat(np.clip(2 + np.arange(h) // repeat_factor + neighborMask[:, 0, 1, 0], 0, pad_pre_alignments.shape[0] - 1).reshape(h, 1), w, axis=1).reshape(h * w)\n",
    "    tj1 = np.repeat(np.clip(2 + np.arange(w) // repeat_factor + neighborMask[0, :, 0, 1], 0, pad_pre_alignments.shape[1] - 1).reshape(1, w), h, axis=0).reshape(h * w)\n",
    "    tj2 = np.repeat(np.clip(2 + np.arange(w) // repeat_factor + neighborMask[0, :, 1, 1], 0, pad_pre_alignments.shape[1] - 1).reshape(1, w), h, axis=0).reshape(h * w)\n",
    "    # Extract the previously estimated motion vectors associeted with those neighbors\n",
    "    ppa1 = pad_pre_alignments[ti1, tj1].reshape((h, w, 2))\n",
    "    ppa2 = pad_pre_alignments[ti2, tj2].reshape((h, w, 2))\n",
    "    # 获得参考帧和备选帧所有可能的瓦片\n",
    "    refTiles = generate_tiles(refer_pyramid, tile_size, 1)\n",
    "    altTiles = generate_tiles(alter_pyramid, tile_size, 1)\n",
    "    # 计算瓦片之间的距离\n",
    "    d0 = computer_tiles_distance(refTiles, altTiles, upsample_alignments).reshape(h * w)\n",
    "    d1 = computer_tiles_distance(refTiles, altTiles, ppa1).reshape(h * w)\n",
    "    d2 = computer_tiles_distance(refTiles, altTiles, ppa2).reshape(h * w)\n",
    "    # 获得候选的运动向量 : 上采样的偏移量、估计的偏移量\n",
    "    candidate_alignments = np.empty((h * w, 3, 2))\n",
    "    candidate_alignments[:, 0, :] = upsample_alignments.reshape(h * w, 2)\n",
    "    candidate_alignments[:, 1, :] = ppa1.reshape(h * w, 2)\n",
    "    candidate_alignments[:, 2, :] = ppa2.reshape(h * w, 2)\n",
    "    # 通过最小化与参考瓦片的L1距离来选择最佳的偏移量\n",
    "    select_alignments = candidate_alignments[np.arange(h * w), np.argmin([d0, d1, d2], axis=0)].reshape((h, w, 2))\n",
    "    if h < refer_pyramid.shape[0] // (tile_size // 2) - 1 or w < refer_pyramid.shape[1] // ( tile_size // 2) - 1:\n",
    "        new_alignments = np.zeros((refer_pyramid.shape[0] // (tile_size // 2) - 1, refer_pyramid.shape[1] // (tile_size // 2) - 1,))\n",
    "        new_alignments[:h, :w] = select_alignments\n",
    "    else:\n",
    "        new_alignments = select_alignments\n",
    "    \n",
    "    return new_alignments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 对齐当前的金字塔层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_pyramid(refer_pyramid, alter_pyramid, up_factor, \n",
    "                  tile_size, pre_tile_size, search_radia, measure=\"L1\", subpixel=True, pre_alignments=None):\n",
    "    if isTypeInt(refer_pyramid):\n",
    "        refer_pyramid = refer_pyramid.astype(np.float32)\n",
    "    if isTypeInt(alter_pyramid):\n",
    "        alter_pyramid = alter_pyramid.astype(np.float32)\n",
    "    # 提取参考帧中的overlap-tiles\n",
    "    refTiles = generate_tiles(refer_pyramid, tile_size, tile_size // 2)\n",
    "    # 使用上采样之前的对齐位移量作为初始guess\n",
    "    if pre_alignments is None:\n",
    "        upsampled_alignments = np.zeros((refTiles.shape[0], refTiles.shape[1], 2), dtype=np.float32)\n",
    "    else:\n",
    "        upsampled_alignments = upsample_alignments(refer_pyramid, alter_pyramid, \n",
    "                                                   pre_alignments, up_factor, tile_size, pre_tile_size)\n",
    "    \n",
    "    h, w = upsampled_alignments.shape[:2]\n",
    "    search_window = 2 * search_radia + 1\n",
    "    \n",
    "    u0 = np.round(upsampled_alignments[:, :, 0]).astype(np.int32)\n",
    "    v0 = np.round(upsampled_alignments[:, :, 1]).astype(np.int32)\n",
    "    \n",
    "    search_areas = generate_tiles(np.pad(alter_pyramid, search_radia, mode=\"constant\", constant_values=2 **16 - 1),\n",
    "                                  tile_size= tile_size + 2 * search_radia)\n",
    "    \n",
    "    # Only keep those corresponding to the area around the reference tile location + [u0, v0]\n",
    "    indI = np.clip(((np.repeat((np.arange(h) * tile_size // 2).reshape(h, 1), w, axis=1)).reshape(h, w) + u0).reshape(h * w), 0, search_areas.shape[0] - 1)\n",
    "    indJ = np.clip(((np.repeat((np.arange(w) * tile_size // 2).reshape(1, w), h, axis=0)).reshape(h, w) + v0).reshape(h * w), 0, search_areas.shape[1] - 1)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
